# üè∑Ô∏è AI-Powered Multi-Agent Document Labeling System

An intelligent document classification system using multiple AI agents to automatically label and categorize documents based on relevance, location, and recency.

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-green.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-red.svg)

## üöÄ Installation

### Prerequisites

- Python 3.9 or higher
- OpenAI API key
- Label Studio URL and API key
- pip package manager
- Git for cloning repository

### Step 1: Clone Repository

```bash
git clone https://github.com/prachibhardwaj0307/Data-Labeling-Agent
cd document-labeling-system
```

### Step 2: Create Virtual Environment

**macOS/Linux:**
```bash
python3 -m venv venv
source venv/bin/activate
```

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

### Step 3: Install Dependencies

```bash
pip install -r requirements.txt
```

Includes OpenAI, Anthropic, Streamlit, python-dotenv, and requests.

### Step 4: Configure Environment

- Create a `.env` file in the project root.
- Add the following lines to the `.env` file:

```
OPENAI_API_KEY=sk-proj-your-api-key-here
LABEL_STUDIO_URL=https://your-label-studio-instance.com
LABEL_STUDIO_API_KEY=your-label-studio-api-key
```

- Replace with your actual OpenAI API key, Label Studio URL, and API key.
- Ensure `.env` is in your `.gitignore` file to prevent committing secrets.

---

## ‚öôÔ∏è Configuration

### Edit `config.py` Settings

**LLM Configuration:**
- `LLM_PROVIDER = "openai"` or `"anthropic"`
- `OPENAI_MODEL = "gpt-4"`
- `TEMPERATURE = 0.3` for consistent results

**Review Limits:**
- `MAX_GROUP_REVIEW_ATTEMPTS = 3`
- `MAX_LABEL_REVIEW_ATTEMPTS = 3`

**Grouping Parameters:**
- `MIN_GROUP_SIZE = 1`
- `MAX_GROUP_SIZE = 10`

---

## üìñ Usage

### Command Line Interface

Run the agent on a specific task from Label Studio using the task ID:

```bash
python3 main.py <task_id>
```

For example:

```bash
python3 main.py 35851
```

Output saved as:
- `output_id_<task_id>.json`
- `report_id_<task_id>.json`

### Streamlit Web UI (Recommended)

Launch the Streamlit application:

```bash
streamlit run streamlit_app.py
```

Then open your browser to [http://localhost:8501](http://localhost:8501)

- Enter the Label Studio **Task ID** in the sidebar input field.
- Click **üöÄ Run Labeling** to start the process.
- View the real-time workflow execution and interim results.
- Manually override any labels if necessary.
- Save the final results back to Label Studio or download them as JSON files.

---

## üí° Label Studio Integration

This project is tightly integrated with Label Studio to streamline the data labeling workflow.

- **Data Loading:** The application fetches tasks directly from Label Studio using the provided Task ID. This eliminates the need for local `input_data.json` files.
- **Annotation:** The agent processes the documents and generates labels based on the defined categories.
- **Example-Based Learning:** The system learns from existing annotations in Label Studio to improve the accuracy of its labeling. Documents already labeled as "relevant," "somewhat_relevant," and "acceptable" are used as reference examples.
- **Saving Results:** The updated labels can be saved back to Label Studio, either by updating an existing annotation or creating a new one.

---

## üìÅ Project Structure

```
data_labeling_agent/
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ filter_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ grouping_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ group_review_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ labeling_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ label_review_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ regroup_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ relabel_agent.py
‚îÇ   ‚îî‚îÄ‚îÄ superior_agent.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ data_models.py
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ helpers.py
‚îÇ   ‚îú‚îÄ‚îÄ label_studio_client.py
‚îÇ   ‚îî‚îÄ‚îÄ llm_client.py
‚îú‚îÄ‚îÄ config.py
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ streamlit_app.py
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env
‚îî‚îÄ‚îÄ README.md
```

---

## üè∑Ô∏è Label Categories

### ‚úÖ RELEVANT (Maximum 10)
- Directly answers query
- Correct location match
- Current year (2025)
- Most comprehensive information
- Automatically limited to top 10

### ‚ö†Ô∏è SOMEWHAT_RELEVANT
- Answers query but older (2024, 2023)
- Partially addresses query
- Correct location
- Still valuable but secondary

### ‚ÑπÔ∏è ACCEPTABLE
- Correct topic but wrong location
- Provides context or background
- Example: US docs when user needs India

### ‚ùì NOT_SURE
- Missing or invalid title
- Unclear content
- Cannot determine relevance confidently

### üö´ IRRELEVANT
- Completely unrelated to query
- Filtered out automatically
- No connection to topic

---

## ü§ñ AI Agents

### SuperiorAgent
- Orchestrates the entire workflow, from data loading and learning to final output generation.

### FilterAgent
- Removes irrelevant documents with reasoning.
- Uses LLM to analyze titles and content.

### GroupingAgent
- Groups documents by topic **and year**.

### GroupReviewAgent
- Reviews grouping quality for coherence and correctness.

### RegroupAgent
- Reorganizes groups based on feedback from the review agent.

### LabelingAgent
- Labels entire groups based on the defined criteria and learns from existing examples.

### LabelReviewAgent
- Enforces the "maximum 10 RELEVANT documents" rule and checks for label consistency.

### RelabelAgent
- Selects the **TOP 10** most relevant documents and downgrades others if necessary.

---

## üîÑ Workflow

**Nine-Step Process:**
1.  Load task from Label Studio.
2.  Learn from existing annotations to create reference examples.
3.  FilterAgent removes irrelevant documents.
4.  GroupingAgent organizes documents by topic and year.
5.  GroupReviewAgent checks the grouping.
6.  RegroupAgent reorganizes groups if necessary.
7.  LabelingAgent assigns labels to the groups.
8.  LabelReviewAgent validates the labels.
9.  RelabelAgent ensures the top 10 relevance rule is met.
10. Generate output and save results to Label Studio or download as JSON.

---

## üì¶ Requirements

```
openai>=1.0.0
anthropic>=0.20.0
streamlit>=1.28.0
python-dotenv>=1.0.0
requests>=2.28.0
```

---

## üìß Contact

**GitHub:** [https://github.com/prachibhardwaj0307/Data-Labeling-Agent](https://github.com/prachibhardwaj0307/Data-Labeling-Agent)

---

‚≠ê **Star this repo if you find it helpful!**
üêõ **Report issues** on the Issues page